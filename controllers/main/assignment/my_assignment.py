import numpy as np
import time
import cv2

import pandas as pd


# from assignment.filter import *
# from assignment.planning import *

# The available ground truth state measurements can be accessed by calling sensor_data[item]. All values of "item" are provided as defined in main.py within the function read_sensors. 
# The "item" values that you may later retrieve for the hardware project are:

# sensor_data å­—å…¸æ•°æ®å†…å®¹ï¼š
# "x_global": Global X position
# "y_global": Global Y position
# "z_global": Global Z position

# 'v_x": Global X velocity
# "v_y": Global Y velocity
# "v_z": Global Z velocity

# "ax_global": Global X acceleration
# "ay_global": Global Y acceleration
# "az_global": Global Z acceleration (With gravtiational acceleration subtracted)

# "roll":  Roll angle (rad)
# "pitch": Pitch angle (rad)
# "yaw":   Yaw angle (rad)

# "q_x": X Quaternion value
# "q_y": Y Quaternion value
# "q_z": Z Quaternion value
# "q_w": W Quaternion value

# sensor_data å…¶ä»–æš‚æ—¶ç”¨ä¸åˆ°çš„æ•°æ®
# "t":
# "range_front"
# "range_left"
# "range_back"
# "range_right"
# "range_down"
# "rate_roll" ...



# A link to further information on how to access the sensor data 
# on the Crazyflie hardware for the hardware practical can be found here: 
# https://www.bitcraze.io/documentation/repository/crazyflie-firmware/master/api/logs/#stateestimate



# å®å®šä¹‰
X = 0 # å››å…ƒæ•°ä¸‹æ ‡
Y = 1
Z = 2
W = 3  
arc2deg = 180/np.pi
deg2arc = np.pi/180

GATE = np.array([
    [2.12, 1.84, 1.24],
    [5.12, 2.30, 0.78],
    [7.20, 3.27, 1.29],
    [5.30, 6.74, 1.19],
    [2.52, 5.50, 1.04]])


# ç”¨æˆ·å®šä¹‰å…¨å±€å˜é‡
Drone_Controller = None
Total_Time       = 0
Draw             = False # æ˜¯å¦ç»˜åˆ¶è¿‡è½¨è¿¹
Explore_State    = 0     # 0 ä»£è¡¨åœ¨æ¢ç´¢ä¸­ï¼Œ1 ä»£è¡¨æ¢ç´¢å®Œæ¯•

########################################## è‡ªå®šåŸºç¡€å‡½æ•° ##########################################

# å‘é‡åŸºç¡€å‡½æ•°

# å‘é‡å•ä½åŒ–
def unit_vector(v):
    norm = np.linalg.norm(v)
    if norm == 0:
        return v  # è¿”å›åŸå§‹å‘é‡
    else:
        return v / norm  # è¿”å›å•ä½åŒ–å‘é‡

# å‘é‡å¤¹è§’
def compute_angle(v1, v2):
    # è®¡ç®—ä¸¤ä¸ªå‘é‡çš„å¤¹è§’ï¼ˆå¼§åº¦ï¼‰
    cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # é™åˆ¶åœ¨ [-1, 1] èŒƒå›´å†…
    return angle

# å››å…ƒæ•°åŸºç¡€å‡½æ•°
def quat_mutiplication(q1, q2):
    # æ ¹æ® [x, y, z, w] çš„å…¬å¼
    x = q1[W]*q2[X] + q1[X]*q2[W] + q1[Y]*q2[Z] - q1[Z]*q2[Y]
    y = q1[W]*q2[Y] - q1[X]*q2[Z] + q1[Y]*q2[W] + q1[Z]*q2[X]
    z = q1[W]*q2[Z] + q1[X]*q2[Y] - q1[Y]*q2[X] + q1[Z]*q2[W]
    w = q1[W]*q2[W] - q1[X]*q2[X] - q1[Y]*q2[Y] - q1[Z]*q2[Z]
    return np.array([x, y, z, w])

def quat_rotate(P1, Q):
    Q_prim = np.array([-Q[X], -Q[Y], -Q[Z], Q[W]])
    P2 = quat_mutiplication(quat_mutiplication(Q,P1),Q_prim)
    return P2

def vector_rotate(p1, Q):
    P1 = np.array([p1[X], p1[Y], p1[Z], 0]) # æ·»åŠ  0
    P2 = quat_rotate(P1, Q)
    return P2[[X,Y,Z]]     # è¿”å›æ—‹è½¬åçš„å‘é‡éƒ¨åˆ†


# ç›®æ ‡ä¸­å¿ƒç‚¹åŸºç¡€å‡½æ•°
def compute_target_center(rect, eps=1e-6):

    # å–å‡ºå››ä¸ªç‚¹
    x0, y0 = rect[0]
    x1, y1 = rect[1]
    x2, y2 = rect[2]
    x3, y3 = rect[3]

    # è®¡ç®—åˆ†æ¯
    denom = (x0 - x2) * (y1 - y3) - (y0 - y2) * (x1 - x3)
    if abs(denom) < eps:
        # åˆ†æ¯æ¥è¿‘0ï¼Œè¯´æ˜ä¸¤ç›´çº¿å¹³è¡Œæˆ–å…±çº¿ï¼Œæ— æ³•ç¡®å®šäº¤ç‚¹
        return None

    # è®¡ç®—åˆ†å­ä¸­çš„é€šé¡¹
    det1 = x0 * y2 - y0 * x2
    det2 = x1 * y3 - y1 * x3

    # è®¡ç®—äº¤ç‚¹åæ ‡
    x = (det1 * (x1 - x3) - (x0 - x2) * det2) / denom
    y = (det1 * (y1 - y3) - (y0 - y2) * det2) / denom

    center = np.array([x, y])

    return center

# å››è¾¹å½¢é‡æ–°æ’åºå‡½æ•°
def SORT(pts):
    """
    è¾“å…¥ï¼š
        pts: numpy æ•°ç»„ï¼Œå½¢çŠ¶ (4,2)ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ª (x,y) åæ ‡
    è¿”å›ï¼š
        æŒ‰ [å·¦ä¸Š, å·¦ä¸‹, å³ä¸‹, å³ä¸Š] æ’åºåçš„ç‚¹ï¼Œå½¢çŠ¶ (4,2)
    """
    # 1. æŒ‰ x åæ ‡å‡åºï¼Œåˆ†æˆå·¦å³ä¸¤ç»„
    pts_sorted = pts[np.argsort(pts[:, 0])]
    left  = pts_sorted[:2]   # x æœ€å°çš„ä¸¤ä¸ª
    right = pts_sorted[2:]   # x æœ€å¤§çš„ä¸¤ä¸ª

    # 2. å·¦ç»„æŒ‰ y å‡åºï¼šä¸Š<ä¸‹ï¼›å³ç»„åŒç†
    left  = left[np.argsort(left[:, 1])]
    right = right[np.argsort(right[:, 1])]

    tl, bl = left    # top-left, bottom-left
    tr, br = right   # top-right, bottom-right

    return np.array([tl, bl, br, tr], dtype=pts.dtype)

# ä¿å­˜æ•°æ®
def save_data(target_pos_list_buffer, file_name = "target_positions"):
    # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰ç›®æ ‡ç‚¹çš„å­—å…¸æ•°æ®
    rows = []

    for frame_idx, targets in enumerate(target_pos_list_buffer):
        for point_idx, point in enumerate(targets):
            rows.append({
                'frame': frame_idx,
                'point_index': point_idx,
                'x': point[0],
                'y': point[1],
                'z': point[2]
            })

    # å°†æ•°æ®è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(rows)

    df.to_csv(f'{file_name}.csv', index=False)

    print("ä¿å­˜ CSV æ–‡ä»¶æˆåŠŸï¼")

# è®¡ç®—2ç‚¹è·ç¦»å‡½æ•°
def compute_distance(P1, P2):
    return np.linalg.norm(P1 - P2)

########################################## è‡ªå®šåŸºç¡€å‡½æ•° ##########################################




# å®šä¹‰æ— äººæœºç±»
class Class_Drone_Controller:

    def __init__(self, sensor_data, camera_data):

        # åŸºæœ¬å‚æ•°
        self.f_pixel = 161.013922282   # ç›¸æœºç„¦è·
        self.vector_Drone2Cam_DroneFrame = np.array([0.03,0.00,0.01]) # æ— äººæœºä¸­å¿ƒåˆ°ç›¸æœºåç§»å‘é‡
        self.camera_size = [300,300]

        self.cam_center_x = self.camera_size[X] / 2 # åƒç´ ä¸­å¿ƒç‚¹ x
        self.cam_center_y = self.camera_size[Y] / 2 # åƒç´ ä¸­å¿ƒç‚¹ y

        self.points_filter_threshold = 0.5 # ç›®æ ‡ç‚¹è¿‡æ»¤é˜ˆå€¼

        # æ— äººæœºä¿¡æ¯
        self.sensor_data     = None  # æ— äººæœºä¼ æ„Ÿå™¨æ•°æ®
        self.camera_data     = None  # ç›¸æœºæ•°æ®
        self.camera_data_BGR = None  # ç›¸æœºæ•°æ® BGR

        # å®æ—¶æ•°æ® (å¤§å†™ä»£è¡¨å®æ—¶æ•°æ®)
        self.Drone_POS_GLOBAL      = None  
        self.Camera_POS_GLOBAL     = None

        self.IMAGE_POINTS_2D       = None  # 2D å›¾åƒæ–¹æ¡†åˆ—è¡¨
        self.IMAGE_TARGET_VEC      = None  # 3D ç›®æ ‡æ–¹å‘
        self.IMAGE_TARGET_VEC_list = []    # 3D ç›®æ ‡æ–¹æ¡†åˆ—è¡¨ï¼Œ0-3ä¸ºçŸ©å½¢çš„å››ä¸ªç‚¹ï¼Œ4ä¸ºä¸­å¿ƒç‚¹

        self.YAW_TARGET    = None
        self.YAW_NORMAL    = None  

        # ç¼“å­˜æ•°æ® (ä¸‰è§’å®šä½)
        self.Drone_Pos_Buffer             = [] # ä½ç½®ç¼“å­˜
        self.Drone_Target_Vec_Buffer      = [] # æ–¹å‘ç¼“å­˜
        self.Drone_Target_Vec_List_Buffer = [] # æ–¹å‘åˆ—è¡¨ç¼“å­˜
        self.min_cumulative_baseline      = 0.5  # è®¾å®šç´¯è®¡åŸºçº¿è·ç¦»é˜ˆå€¼ #00FF00

        self.target_pos_list_buffer = [] # ç›®æ ‡ç‚¹ 4+1 åˆ—è¡¨
        self.target_pos_list_Valid  = [] # ç›®æ ‡ç‚¹ 4+1 åˆ—è¡¨    [æ•°æ®å¤„ç†å]

        # è·¯å¾„æ•°æ®è®°å½•
        self.RACING_POINTS_COMMAND = []

        self.AT_GATE             = False # æ˜¯å¦åˆ°è¾¾ Gate
        self.EXAMING             = True
        self.RACING_EXPLORE      = 0     

        self.RACING_POINT_INDEX  = [] # è®°å½•ç´¢å¼•ï¼Œç”¨äºè®°å½• æŸä¸ªGate èµ·å§‹ index

        # è§†è§‰å‘½ä»¤é”
        self.LOCK = False
        self.IMG_LAST_DIRECTION = None # ä¸Šä¸€ä¸ªè§†è§‰æ–¹å‘

        # å·¡èˆª
        self.RACING_INDEX = 0
        self.RACING_PATH  = None

        self.timer = None # åŸºäºæ—¶é—´çš„å‚æ•°
        self.racing_path  = None 
        self.racing_time  = None

        # èµ·é£çŠ¶æ€
        self.takeoff = False

        # å¯åŠ¨å‡½æ•°
        self.update(sensor_data, camera_data)  # æ›´æ–°æ•°æ®
        self.Record_Start_Point_command()      # è®°å½•èµ·å§‹ä½ç½®
        self.Generate_Scan_Sequence()          # ç”Ÿæˆæ‰«æåç§»åºåˆ—

    ########################################## æ›´æ–°å‡½æ•° ##########################################

    #00FF00 æ›´æ–°æ— äººæœºä½ç½® + æ›´æ–°ç›¸æœºæ•°æ® #00FF00
    def update(self, sensor_data, camera_data):
        
        # æ›´æ–°æ•°æ® + ç›¸æœº
        self.sensor_data  = sensor_data
        self.camera_data  = camera_data

        # åŸå§‹å›¾åƒè½¬ä¸º BGR å›¾åƒï¼ˆå¿½ç•¥ Alpha å›¾å±‚ï¼‰
        b, g, r, a           = cv2.split(self.camera_data)
        bgr_image            = cv2.merge([b, g, r])
        self.camera_data_BGR = bgr_image

        # æ›´æ–°ä½ç½® + ç›¸æœºç›®æ ‡
        self.update_drone_quat()                        # æ›´æ–°æ— äººæœºå››å…ƒæ•°
        self.update_drone_position_global()             # æ›´æ–°æ— äººæœºåæ ‡
        self.update_camera_position_global()            # æ›´æ–°ç›¸æœºåæ ‡
        self.update_IMAGE_TO_VEC_LIST(DEBUG = True)     # ç›¸æœºåæ ‡ç³»ä¸‹ç›®æ ‡ä½ç½®åˆ—è¡¨


        # æ›´æ–° ä¸‰è§’å®šä½ 4+1 åˆ—è¡¨
        self.update_Target_List_with_Buffer()               # æ›´æ–°ç›®æ ‡ç‚¹åˆ—è¡¨ [slef.target_pos_list_buffer] åˆ—è¡¨æ•°æ®
        #  self.update_Target_list_Filtered_CallBack()      # æ•°æ®æ»¤æ³¢
        #    self.check_target_switch() # æ£€æµ‹ç›®æ ‡åˆ‡æ¢       # æ˜¯å¦åˆ‡æ¢ç›®æ ‡

        # æ£€æµ‹
        self.check_target_AtGate()                       # æ£€æµ‹ç›®æ ‡ç‚¹æ˜¯å¦åˆ°è¾¾
        # self.check_target_switch()                       # æ£€æµ‹ç›®æ ‡åˆ‡æ¢
        self.check_is_near_gate_Vision(DEBUG = False)


        # æ›´æ–° YAW è§’åº¦
        self.Compute_YAW_TARGET() # [ä¾èµ– update_IMAGE_TO_VEC_LIST] 
        self.Compute_YAW_NORMAL() # [ä¾èµ– update_Target_List_with_Buffer]

    ########################################## ä¼ æ„Ÿå™¨å‡½æ•° ##########################################
    def update_drone_quat(self):
        quat = np.array([self.sensor_data['q_x'], 
                         self.sensor_data['q_y'], 
                         self.sensor_data['q_z'], 
                         self.sensor_data['q_w']])
        self.Q = quat.copy()  # å¤åˆ¶å››å…ƒæ•°

    def update_drone_position_global(self):
        position = np.array([self.sensor_data['x_global'], 
                             self.sensor_data['y_global'], 
                             self.sensor_data['z_global']])
        self.Drone_POS_GLOBAL = position
        return position

    def update_camera_position_global(self):
        P_Drone_global = self.Drone_POS_GLOBAL      # æ— äººæœºå…¨å±€åæ ‡ç³»ä¸‹ä½ç½®
        Q_Drone2World  = self.Q                     # æ— äººæœºå››å…ƒæ•°
        P_Drone2Cam_Shift_global = vector_rotate(self.vector_Drone2Cam_DroneFrame, Q_Drone2World)  # æ— äººæœºåæ ‡ç³»ä¸‹ç›¸æœºä½ç½®
        P_Cam_global   = P_Drone_global + P_Drone2Cam_Shift_global     
        self.Camera_POS_GLOBAL =  P_Cam_global   # ç›¸æœºå…¨å±€åæ ‡ç³»ä¸‹ä½ç½®
    
    ########################################## çŠ¶æ€æ£€æµ‹å‡½æ•° ##########################################
    
    # åŸºäºè·ç¦»æ£€æµ‹
    def check_target_AtGate(self):
        
        if self.AT_GATE:
            return True
        
        else:
            try:
                target_pos = self.target_pos_list_Valid[-1][4]   # ç›®æ ‡ä½ç½®
                drone_pos  = self.update_drone_position_global() # æ— äººæœºä½ç½®

                dist = compute_distance(target_pos, drone_pos)   # è®¡ç®—è·ç¦»

                # åˆ°è¾¾ç›®æ ‡ç‚¹èŒƒå›´
                if dist <= 0.5:  #00FF00 åç»­éœ€è¦è°ƒæ•´

                    # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°åˆ°è¾¾èŒƒå›´
                    self.AT_GATE = True   

                    print("åˆ°è¾¾ç›®æ ‡ç‚¹èŒƒå›´ï¼")

                    return True
                
                else:
                    self.AT_GATE = False # é‡æ–°å¼€å§‹
                    return False
                
            except IndexError:
                return False
    
    # åŸºäºæ£€æµ‹ä½ç½®çªå˜
    def check_target_switch(self):
        
        if len(self.target_pos_list_Valid) == 0:
            return False
        
        if len(self.target_pos_list_Valid) != 0:

            # æ£€æµ‹ä» 0-> 1 çš„çªå˜
            if len(self.target_pos_list_Valid) == 1:
                self.RACING_EXPLORE += 1
                self.RACING_POINT_INDEX.append(0) # è®°å½•ç´¢å¼•
                print(self.RACING_EXPLORE-1, "->", self.RACING_EXPLORE, "ç›®æ ‡ç‚¹åˆ‡æ¢ï¼")  

                self.AT_GATE = False # é‡æ–°å¼€å§‹

                return True

            # æ£€æµ‹åˆ°ä¸‹ä¸€ä¸ªç‚¹
            if len(self.target_pos_list_Valid) >= 2:
                prev = self.target_pos_list_Valid[-2][4]  # ç›®æ ‡ä½ç½®
                curr = self.target_pos_list_Valid[-1][4]  # ç›®æ ‡ä½ç½®
                delta = compute_distance(prev, curr) # è®¡ç®—ç›®æ ‡ç‚¹å·®å€¼

                if delta >= 2.0: 
                    self.RACING_EXPLORE += 1
                    self.RACING_POINT_INDEX.append(len(self.target_pos_list_Valid) - 1)
                    print(self.RACING_EXPLORE-1, "->", self.RACING_EXPLORE, "ç›®æ ‡ç‚¹åˆ‡æ¢ï¼") 

                    self.AT_GATE = False # é‡æ–°å¼€å§‹

                    return True
                else:
                    return False        


    # åŸºäºå›¾åƒè¯†åˆ«
    # æ£€æµ‹ç²‰è‰²æ˜¯å¦å‡ºç°åœ¨è¾¹ç¼˜
    def check_is_near_gate_Vision(self, DEBUG = False):
        """
        æ£€æµ‹è¾“å…¥çš„äºŒç»´ç‚¹é›†åˆï¼ˆå¦‚ (N,2) çš„ numpy æ•°ç»„ï¼‰ä¸­æ˜¯å¦è‡³å°‘æœ‰ä¸¤ä¸ªç‚¹çš„ X æˆ– Y åæ ‡ç­‰äº 0 æˆ– 300ã€‚
        """
        if self.IMAGE_POINTS_2D is not None:
            pts = self.IMAGE_POINTS_2D[0:4] # å–å‡ºå››ä¸ªç‚¹

            count = 0
            for pt in pts:
                x, y = pt
                if x < 2 or x > 298 or y < 2 or y > 298:
                    count += 1
            if count >= 2:
                if DEBUG:
                    print("æ£€æµ‹åˆ°æ–¹å½¢è¶…å‡ºè¾¹æ¡†")
                return True
            else:
                return False
        else:
            return False
    ########################################## åæ ‡å˜æ¢å‡½æ•° ##########################################
    def Convert_Frame_Drone2World(self, P_DroneFrame):
        Q_Drone2World = self.Q  
        P_WorldFrame  = vector_rotate(P_DroneFrame, Q_Drone2World)    # Body Frame -> World Frame
        return P_WorldFrame

    def Convert_Frame_Cam2Drone(self, P_CamFrame):
        cam_delta_x = P_CamFrame[0] - self.cam_center_x
        cam_delta_y = P_CamFrame[1] - self.cam_center_y
        vector_DroneFrame = np.array([self.f_pixel, -cam_delta_x, -cam_delta_y])
        return vector_DroneFrame

    def Convert_Frame_CamNormal(self, P_CamFrame):
        cam_delta_x = P_CamFrame[0] - self.cam_center_x
        cam_delta_y = P_CamFrame[1] - self.cam_center_y
        vector_DroneFrame = np.array([cam_delta_x, -cam_delta_y])
        return vector_DroneFrame
    ########################################## å›¾åƒå¤„ç†å‡½æ•° ##########################################
    # å›¾åƒ -> ç²‰è‰² mask
    def img_BGR_to_PINK(self, DEBUG = False):

        bgr = self.camera_data_BGR.copy()

        # OpenCV æ˜¯ BGR é¡ºåºï¼
        upper_pink  = np.array([255, 185, 255])  # B, G, R
        lower_pink  = np.array([190, 55, 190])   
        binary_mask = cv2.inRange(bgr, lower_pink, upper_pink)

        # å¯è§†åŒ– mask å’Œæå–ç»“æœ
        if DEBUG:
            pink_only = cv2.bitwise_and(bgr, bgr, mask=binary_mask)      # åº”ç”¨ mask æ‰£å›¾
            cv2.imshow("Pink", pink_only)                                # ç²‰è‰²å›¾

        return binary_mask

    # å›¾åƒ -> ç‰¹å¾ç‚¹
    def update_IMAGE_TO_POINTS_2D(self, binary_mask, DEBUG = False):
        
        # 1.è½®å»“æå–
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # 2.è½®å»“è¿‘ä¼¼ (éå†æ‰€æœ‰è½®å»“ï¼Œæ‰¾åˆ°æ‹Ÿåˆä¸ºå››è¾¹å½¢ä¸”é¢ç§¯æœ€å¤§çš„é‚£ä¸ª)
        largest_rect = None
        max_area = 0  # ç”¨äºè®°å½•å½“å‰æœ€å¤§çš„é¢ç§¯
        for cnt in contours:
            # è®¡ç®—è½®å»“å‘¨é•¿
            peri = cv2.arcLength(cnt, True)

            # å¤šè¾¹å½¢æ‹Ÿåˆï¼Œepsilon æ§åˆ¶æ‹Ÿåˆç²¾åº¦ï¼Œé€šå¸¸æ˜¯å‘¨é•¿çš„ 1-5%
            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)

            # åˆ¤æ–­æ˜¯å¦æ˜¯å››è¾¹å½¢
            if len(approx) == 4:
                area = cv2.contourArea(approx)
                if area > max_area:
                    max_area = area
                    largest_rect = approx
            
        # å¤åˆ¶å¸§ï¼Œé˜²æ­¢é—ªçƒ
        Feature_Frame = self.camera_data_BGR.copy()

        # ç‰¹å¾ç‚¹æå–
        if largest_rect is not None:
            largest_rect     = np.squeeze(largest_rect, axis=1)                     # å°† 4x1x2 çš„æ•°ç»„è½¬æ¢ä¸º 4x2 çš„æ•°ç»„
            rect_center      = compute_target_center(largest_rect)                  # np.Float64
            largest_rect     = SORT(largest_rect)                                   # ç‚¹æ’åº
            target_rect      = np.append(largest_rect, [rect_center], axis = 0)     # æ·»åŠ ä¸­å¿ƒç‚¹

            # æ›´æ–°å›¾åƒç‚¹
            self.IMAGE_POINTS_2D = target_rect
        
        else:
            self.IMAGE_POINTS_2D = None # æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡

        # æ˜¯å¦ç”»å›¾
        if DEBUG and self.IMAGE_POINTS_2D is not None:
            length = len(self.IMAGE_POINTS_2D)
            increment = int(255/(length+1))  # è®¡ç®—å¢é‡
            green_value = increment
            for x, y in self.IMAGE_POINTS_2D:
                cv2.circle(Feature_Frame, (int(x), int(y)), 5, (0, green_value, 0), -1)
                green_value += increment
            cv2.imshow("Rectangle Corners", Feature_Frame)
        else:
            cv2.imshow("Rectangle Corners", Feature_Frame)



    # å›¾åƒ -> æ–¹å‘å‘é‡åˆ—è¡¨
    def update_IMAGE_TO_VEC_LIST(self, DEBUG = False):

        # åˆå§‹åŒ–
        Vector_Cam2Target_WorldFrame_list = []

        # å›¾åƒå¤„ç†
        cv2.waitKey(1) # å¦‚æœæ”¾åœ¨ return åé¢ä¼šæŠ¥é”™
        binary_mask = self.img_BGR_to_PINK(DEBUG)            # æŠ å›¾
        self.update_IMAGE_TO_POINTS_2D(binary_mask, DEBUG)   # æ›´æ–°å›¾åƒ2Dç‰¹å¾ç‚¹
        
        # è®¡ç®—å‘é‡
        if self.IMAGE_POINTS_2D is not None:
            
            for cam_point in self.IMAGE_POINTS_2D:
                # ç›®æ ‡æ–¹å‘ï¼šç›¸æœºåæ ‡ç³» -> æ— äººæœºåæ ‡ç³»
                Vector_Cam2Target_DroneFrame = self.Convert_Frame_Cam2Drone(cam_point)    
                Vector_Cam2Target_DroneFrame = unit_vector(Vector_Cam2Target_DroneFrame)  

                # ç›®æ ‡æ–¹å‘ï¼šæ— äººæœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³»
                Vector_Cam2Target_WorldFrame = self.Convert_Frame_Drone2World(Vector_Cam2Target_DroneFrame)
                Vector_Cam2Target_WorldFrame = unit_vector(Vector_Cam2Target_WorldFrame)  

                Vector_Cam2Target_WorldFrame_list.append(Vector_Cam2Target_WorldFrame)    # æ·»åŠ åˆ°åˆ—è¡¨ä¸­

            self.IMAGE_TARGET_VEC_list = Vector_Cam2Target_WorldFrame_list 

        else :
            self.IMAGE_TARGET_VEC_list = None


    ########################################## ä¸‰è§’å®šä½éƒ¨åˆ† ######################################################
    def triangular_positioning(self,
                           P_WorldFrame_New, 
                           P_WorldFrame_Old,
                           Vector_Direct_Cam2Target_WorldFrame_New,
                           Vector_Direct_Cam2Target_WorldFrame_Old): 

        # å¦‚æœæ–¹å‘å‘é‡è¿‡äºæ¥è¿‘ï¼Œè¿”å› None
        if np.array_equal(Vector_Direct_Cam2Target_WorldFrame_New, Vector_Direct_Cam2Target_WorldFrame_Old):
            return None
        else:
            # é‡å‘½å
            r0 = Vector_Direct_Cam2Target_WorldFrame_Old
            r1 = Vector_Direct_Cam2Target_WorldFrame_New
            P0 = P_WorldFrame_Old
            P1 = P_WorldFrame_New

            # æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„
            A = np.array([[r0 @ r0, -r0 @ r1],
                          [r0 @ r1, -r1 @ r1]])
            b = np.array([[r0 @ (P1 - P0)],
                          [r1 @ (P1 - P0)]])
            
            try:
                x, _, _, _ = np.linalg.lstsq(A, b, rcond=None) # æœ€å°äºŒä¹˜æ³•æ±‚è§£ï¼Œæ›´ç¨³å®š
            except np.linalg.LinAlgError:
                print("Error: Singular matrix, cannot solve the system of equations.")
                return None

            # è®¡ç®—ç›®æ ‡ä½ç½®
            T0 = P0 + x[0] * r0
            T1 = P1 + x[1] * r1
            T = (T0 + T1) / 2

        return T

    ############################################# ä¸‰è§’å®šä½ï¼Œç¼“å­˜æ›´æ–° ############################################# 
    def update_Target_List_with_Buffer(self):

        # å¦‚æœè§†é‡å†…æ— ç›®æ ‡ï¼Œä¸èƒ½å°† None æ·»åŠ åˆ°ç¼“å­˜ä¸­
        # #0000FF å¤§å†™ä»£è¡¨å®æ—¶æ›´æ–°æ•°æ®ï¼Œå®æ—¶æ•°æ®ä¼šåŒ…å« None #0000FF
        if (self.Drone_POS_GLOBAL is not None) and (self.IMAGE_TARGET_VEC_list is not None) and (not self.check_is_near_gate_Vision()):

            # åŒæ—¶æ›´æ–° Buffer
            self.Drone_Pos_Buffer.append(self.Drone_POS_GLOBAL)
            self.Drone_Target_Vec_List_Buffer.append(self.IMAGE_TARGET_VEC_list)
        
        # è‡³å°‘ä¸¤å¸§æ•°æ®
        if len(self.Drone_Pos_Buffer) >= 2: 

            # è®¡ç®— ä½ç§» + è§’åº¦å˜åŒ–
            dist_difference  = np.linalg.norm(self.Drone_Pos_Buffer[-1] - self.Drone_Pos_Buffer[0])
            angle_differnece = compute_angle(self.Drone_Target_Vec_List_Buffer[-1][4], self.Drone_Target_Vec_List_Buffer[0][4])

            # ç§»åŠ¨è·ç¦»å¤§äº æœ€å°è®¾å®šå€¼
            # 1.æ›´æ–° List_Buffer
            # 2.å›è°ƒå‡½æ•°æ»¤æ³¢ List_Filtered
            if dist_difference >= self.min_cumulative_baseline and angle_differnece >= 0.01:
                
                # åˆå§‹åŒ–
                Target_Pos_list = np.zeros((5,3)) # 5 ä¸ªç›®æ ‡ä½ç½®

                # è®¡ç®— 5 ä¸ªç›®æ ‡ä½ç½®
                for i in range(5):
                    Target_Pos_list[i] = self.triangular_positioning(self.Drone_Pos_Buffer[-1], 
                                                                 self.Drone_Pos_Buffer[0],
                                                                 self.Drone_Target_Vec_List_Buffer[-1][i],
                                                                 self.Drone_Target_Vec_List_Buffer[0][i])

                # ç¼“å­˜æ¸…ç©º #FF0000 éœ€è¦ä¿®æ”¹é€»è¾‘ï¼Œå……åˆ†åˆ©ç”¨æ•°æ®
                self.Drone_Pos_Buffer             = [] # æ¸…ç©ºç¼“å­˜
                self.Drone_Target_Vec_List_Buffer = []

                # æ›´æ–°ç›®æ ‡å€¼
                self.target_pos_list_buffer.append(Target_Pos_list) # ç›®æ ‡ç¼“å­˜

                # å›è°ƒå‡½æ•°æ»¤æ³¢
                self.update_Target_list_Filtered_CallBack() # ç›®æ ‡ç‚¹æ•°æ®å¤„ç†å‡½æ•°




    # Filter å‡½æ•° (ä¸‰è§’å®šä½ ç›®æ ‡ç‚¹æ•°æ® å¤„ç†å‡½æ•°) ğŸ‘†
    # ä½œä¸ºå›è°ƒå‡½æ•°ï¼Œåœ¨æ¯æ¬¡ self.target_pos_list_buffer æ›´æ–°æ—¶è¢«è°ƒç”¨
    # å¦åˆ™å¦‚æœ self.target_pos_list_buffer ä¸æ›´æ–°ï¼Œå¹¶ä¸”æœ€åä¸¤ä¸ªæ•°æ®æ¥è¿‘ï¼Œåˆ™ä¼šä¸€ç›´æ·»åŠ åˆ° self.target_pos_list_Valid ä¸­
    def update_Target_list_Filtered_CallBack(self):
        if len(self.target_pos_list_buffer) >= 2:
            P_new = self.target_pos_list_buffer[-1][4] # æœ€æ–°ç›®æ ‡ç‚¹
            P_old = self.target_pos_list_buffer[-2][4] # ä¸Šä¸€ä¸ªç›®æ ‡ç‚¹
            P_Diff = compute_distance(P_new, P_old)    # è®¡ç®—å˜åŒ–é‡

            # è¿‡æ»¤ç›®æ ‡ç‚¹
            if P_Diff <= 0.2:
                self.target_pos_list_Valid.append(self.target_pos_list_buffer[-1]) # ç›®æ ‡ç‚¹ 4+1 ç¼“å­˜

                self.check_target_switch() # æ£€æµ‹ç›®æ ‡åˆ‡æ¢

                #FF0000 æµ‹è¯• æ‰“å°ä¸­å¿ƒç‚¹
                # print(self.target_pos_list_Valid[-1][4])

    ############################################# è®¡ç®—ç›®æ ‡ YAW #############################################
    def Compute_YAW_TARGET(self):
        if self.IMAGE_TARGET_VEC_list is not None:
            Vector_3D = self.IMAGE_TARGET_VEC_list[4]
            self.YAW_TARGET = np.arctan2(Vector_3D[1], Vector_3D[0])  # è®¡ç®— YAW è§’åº¦
        else: 
            return None
    
    def Compute_YAW_NORMAL(self):

        # points_global = self.target_pos_list_buffer[-1]

        if len(self.target_pos_list_buffer) > 0:
            # points_global = np.mean(self.target_pos_list_buffer, axis=0) # è®¡ç®—å¹³å‡å€¼
            points_global = self.target_pos_list_buffer[-1]

            vec1 = points_global[0] - points_global[3]
            vec2 = points_global[1] - points_global[2]
            vec = 0.5*(vec1 + vec2) 
            theta = np.arctan2(vec[1], vec[0])  # è®¡ç®— YAW è§’åº¦

            normal_angle = theta - np.pi / 2
            normal_vector = np.array([np.cos(normal_angle), np.sin(normal_angle), 0]) #FF0000 æ³¨æ„è¿™ä¸ªæ˜¯ä¸ç²¾ç¡®çš„æ³•å‘é‡

            self.YAW_NORMAL = normal_angle 
            self.Drone_YAW_NORMAL_VEC = normal_vector

    ############################################## ç›®æ ‡ç‚¹è®°å½•å‡½æ•° ##############################################

    # è®°å½•èµ·ç‚¹ä½ç½®
    def Record_Start_Point_command(self):
        POS = self.update_drone_position_global()
        YAW = self.sensor_data['yaw']

        point_data = np.array([POS[X], POS[Y], POS[Z], YAW])

        self.RACING_POINTS_COMMAND.append(point_data)
    

    ############################################ è§†è§‰å¯¼èˆª ##############################################

    # å¸¸æ•°åç§»
    def constant_drift_in_Y(self):

        Drift_Direction_DroneFrame = np.array([0, -1, 0])
        Drift_Direction_WorldFrame = self.Convert_Frame_Drone2World(Drift_Direction_DroneFrame) # æ— äººæœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³»

        return Drift_Direction_WorldFrame
    
    # è®¡ç®— ç›®æ ‡-æ— äººæœº è·ç¦»
    def compute_distance_drone_to_target(self):
        dist = 0.0
        if len(self.target_pos_list_Valid) > 0:
            target_pos = self.target_pos_list_Valid[-1][4]
            drone_pos  = self.Drone_POS_GLOBAL
            dist = np.linalg.norm(target_pos - drone_pos)    # è®¡ç®—è·ç¦»
        return dist

    # ç³»æ•°è¡°å‡
    def coefficient_drift_in_Y(self, Dist_Threshold = 1.0, Tensity = 0.8, n = 4):

        x = self.compute_distance_drone_to_target()

        x = np.asarray(x, dtype=float)
        f = np.zeros_like(x)
        mask1 = x >= Dist_Threshold
        mask2 = (x >= 0) & (x < Dist_Threshold)
        f[mask1] = Tensity
        f[mask2] = Tensity * (x[mask2] / Dist_Threshold)**n

        return f # å¤šé¡¹å¼è¡°å‡å‡½æ•°

    # è®¡ç®—æ–¹æ¡†åè½¬è§’åº¦ -> åç§»é€Ÿåº¦
    def drift_speed_in_Y(self):

        drift_velocuty = np.array([0, 0, 0]) 

        if self.IMAGE_POINTS_2D is None:
            return np.array([0, 0, 0])

        p0 = self.IMAGE_POINTS_2D[0] # å·¦ä¸Šè§’
        p1 = self.IMAGE_POINTS_2D[1]
        p2 = self.IMAGE_POINTS_2D[2]
        p3 = self.IMAGE_POINTS_2D[3]

        # å·¦å³è¾¹
        length_L = np.linalg.norm(p0 - p1) 
        length_R = np.linalg.norm(p2 - p3) 

        # ä¸Šä¸‹è¾¹
        length_T = np.linalg.norm(p0 - p3)
        length_B = np.linalg.norm(p1 - p2)
        length_horizontal = 0.5*(length_T + length_B) # ä¸Šä¸‹è¾¹å¹³å‡å€¼
        
        # æ•°æ®ä¸åˆæ³•
        if length_horizontal / length_L > 1 or length_horizontal / length_R > 1:
            return np.array([0, 0, 0])

        # è®¡ç®—è§’åº¦
        angle_L = np.arccos(length_horizontal / length_L) # å·¦è¾¹è§’åº¦
        angle_R = np.arccos(length_horizontal / length_R) # å³è¾¹è§’åº¦

        # 
        GAIN = 7

        # è®¡ç®—åç§»é€Ÿåº¦
        if length_L > length_R:
            drift_velocuty = np.array([0, -1, 0]) * GAIN*(angle_L / np.pi) # å·¦è¾¹åç§»é€Ÿåº¦
            drift_velocuty = self.Convert_Frame_Drone2World(drift_velocuty) # æ— äººæœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³»
        else:
            drift_velocuty = np.array([0, +1, 0]) * GAIN*(angle_R / np.pi)
            drift_velocuty = self.Convert_Frame_Drone2World(drift_velocuty) # æ— äººæœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³»

        # print(angle_L / np.pi, angle_R / np.pi)

        return drift_velocuty 
        

    # è§†è§‰æŒ‡ä»¤ - æ€»å‡½æ•°
    def IMG_command(self):

        # ä½¿ç”¨è¯¥å‘½ä»¤éœ€è¦ç¡®ä¿ çœ‹åˆ°ç›®æ ‡ 
        direction_target = self.IMAGE_TARGET_VEC_list[4]

        POS = self.update_drone_position_global()
        POS = POS + direction_target * 1.0 + self.drift_speed_in_Y() * self.coefficient_drift_in_Y(Dist_Threshold=1.0, Tensity=0.8) # ç›®æ ‡ä½ç½® + åç§»é‡ #FF0000  
        YAW = self.YAW_TARGET

        command = [POS[X], POS[Y], POS[Z], YAW] # ç›®æ ‡ä½ç½® + YAW

        return command

    # è§†è§‰å¯¼èˆª
    def get_IMG_command(self):
        # å¦‚æœæ²¡çœ‹åˆ°ç²‰è‰² -> æ‰«ææ¨¡å¼
        if self.IMAGE_POINTS_2D is None:
            control_command = Drone_Controller.Start_Scan_Command() 

        # å¦‚æœçœ‹åˆ°ç²‰è‰² -> è·Ÿè¸ªæ¨¡å¼
        elif (self.IMAGE_POINTS_2D is not None):
            self.scan_FLAG_RESTART = True        # é‡å¯æ‰«ææ ‡å¿—ä½
            control_command = Drone_Controller.IMG_command() # è§†è§‰æŒ‡ä»¤
        
        return control_command

    ############################################### å®šä½å¯¼èˆª ##############################################
    def stay(self):
        return [self.Drone_POS_GLOBAL[X], self.Drone_POS_GLOBAL[Y], self.Drone_POS_GLOBAL[Z], self.sensor_data['yaw']]

    def get_triangulate_command(self):

        # ç›´æ¥å– target_pos_list_Valid ä¸­çš„æœ€åä¸€ä¸ªç‚¹
        if len(self.target_pos_list_Valid) > 0:
            target_pos = self.target_pos_list_Valid[-1][4]
            target_YAW = self.YAW_TARGET
            command = np.append(target_pos, target_YAW) # ç›®æ ‡ä½ç½® + YAW
            return command.tolist()
        else:
            return self.stay()


    def get_mix_command(self):
        
        # é»˜è®¤å‘½ä»¤ä¸º è§†è§‰å‘½ä»¤
        sign = "å®šä½"
        command = self.get_triangulate_command()
        
        # å¦‚æœåˆ°è¾¾ç›®æ ‡ç‚¹
        if self.check_target_AtGate():
            # åˆ°è¾¾ç›®æ ‡ç‚¹ï¼Œä½¿ç”¨è§†è§‰å‘½ä»¤
            command = self.get_IMG_command()
            sign = "è§†è§‰"
        
        else:
            # ç›®æ ‡åˆ‡æ¢ï¼Œä½¿ç”¨ä¸‰è§’å®šä½å‘½ä»¤
            command = self.get_triangulate_command()

        print("Command: ", sign)
        
        return command
    ############################################### æ‰«ææ¨¡å¼ ##############################################
    def Generate_Scan_Sequence(self):
        T  = 18
        dt = 0.01

        t_sequence = np.arange(0, T + dt, dt) # ç”Ÿæˆæ—¶é—´åºåˆ—

        YAW_shift    = 20 * deg2arc     # æ‰«æ éœ‡è¡è§’åº¦
        delta_YAW    = 360 * deg2arc    # æ‰«æ éœ‡è¡è§’åº¦
        delta_height = 0.0              # æ‰«æ éœ‡è¡é«˜åº¦

        omega = 2*np.pi/T

        self.scan_index        = 0    # åˆå§‹åŒ–ç´¢å¼•
        self.scan_FLAG_RESTART = True # åˆå§‹åŒ–é‡å¯æ ‡å¿— 
        self.scan_max_index    = T/dt
        self.squence_Shift_YAW    = np.sin( omega * t_sequence) * delta_YAW / 2  + YAW_shift
        self.squence_Shift_Height = np.sin( omega * t_sequence) * delta_height / 2
    
    def Start_Scan_Command(self):

        # å¦‚æœä¸Šä¸€ä¸ªçŠ¶æ€ä¸æ˜¯ Scanï¼Œåˆ™è®°å½• å½“å‰ POS + YAWï¼Œä½œä¸ºæ‰«æ
        if self.scan_FLAG_RESTART:
            self.scan_index = 0
            self.scan_FLAG_RESTART = False

            self.scan_POS = self.update_drone_position_global()
            self.scan_YAW = self.sensor_data['yaw']
        
        # å‘¨æœŸæ€§æ‰«æ
        if self.scan_index >= self.scan_max_index:
            self.scan_index = 0

        command = [self.scan_POS[X],
                   self.scan_POS[Y],
                   self.scan_POS[Z] + self.squence_Shift_Height[self.scan_index], # é«˜åº¦
                   self.scan_YAW    + self.squence_Shift_YAW[self.scan_index]]
        
        self.scan_index += 1

        return command

    ############################################### åŸºäºä½ç½®çš„ å·¡èˆªæ¨¡å¼ ##############################################
    def get_Racing_command_POS_BASED(self):
        
        
        # å¦‚æœåœ¨ index å†…
        try:
            command = self.RACING_PATH[self.RACING_INDEX]

            try: 
                pos1 = self.RACING_PATH[self.RACING_INDEX]
                pos2 = self.RACING_PATH[self.RACING_INDEX + 1]

                yaw = np.arctan2(pos2[1] - pos1[1], pos2[0] - pos1[0]) # è®¡ç®— YAW è§’åº¦

                command[3] = yaw # ç›®æ ‡ä½ç½® + YAW

            except IndexError:
                yaw = self.sensor_data['yaw'] # å½“å‰ YAW è§’åº¦
                command[3] = yaw              # ç›®æ ‡ä½ç½® + YAW

            command = command.tolist() # è½¬æ¢ä¸ºåˆ—è¡¨

            # self.RACING_INDEX += 1

        # å¦‚æœä¸åœ¨ index å†…
        except IndexError:
            command = self.stay()
        
        
        # æ§åˆ¶å‘½ä»¤ä¸€è‡´æ€§
        Current_Pos = self.Drone_POS_GLOBAL
        Target_Pos  = command[0:3]
        distance = compute_distance(Current_Pos, Target_Pos) # è®¡ç®—è·ç¦»

        if distance < 1.5: # åˆ°è¾¾ç›®æ ‡ç‚¹èŒƒå›´
            self.RACING_INDEX += 1

        return command


    #  ############################################### åŸºäºæ—¶é—´çš„ å·¡èˆªæ¨¡å¼ ##############################################
    def get_Racing_command_TIME_BASED(self, dt):

        # åˆå§‹åŒ–
        if self.timer is None:
            self.timer = 0.0
            self.index_current_setpoint = 0

        # åˆå§‹åŒ–å
        if self.timer is not None:
            
            # è®¡ç®—ç›®æ ‡ä½ç½®
            # path_points ç´¢å¼•æ²¡ç”¨å®Œ
            try:
                # Update new setpoint
                if self.timer >= self.racing_time[self.index_current_setpoint]:
                    self.index_current_setpoint += 1
                current_setpoint = self.racing_path[self.index_current_setpoint,:]
            
            # path_points ç´¢å¼•ç”¨å®Œäº†
            except IndexError:
                current_setpoint = self.racing_path[-1]


            # è®¡ç®— ç›®æ ‡YAW
            try: 
                pos1 = self.RACING_PATH[self.index_current_setpoint]
                pos2 = self.RACING_PATH[self.index_current_setpoint + 1]

                yaw = np.arctan2(pos2[1] - pos1[1], pos2[0] - pos1[0]) # è®¡ç®— YAW è§’åº¦

                current_setpoint[3] = yaw # ç›®æ ‡ä½ç½® + YAW

            except IndexError:
                yaw = self.sensor_data['yaw'] # å½“å‰ YAW è§’åº¦
                current_setpoint[3] = yaw              # ç›®æ ‡ä½ç½® + YAW
            
            # æ›´æ–°è·¯å¾„æ—¶é—´
            self.timer += dt
                    
        return current_setpoint.tolist() # è½¬æ¢ä¸ºåˆ—è¡¨









# æ— äººæœºæ§åˆ¶å‡½æ•°
def get_command(sensor_data,  # ä¼ æ„Ÿå™¨æ•°æ® (è¯¦è§ä¸Šé¢çš„ä¿¡æ¯)
                camera_data,  # ç›¸æœºæ•°æ®
                dt,           # dt
                ):

    # NOTE: Displaying the camera image with cv2.imshow() will throw an error because GUI operations should be performed in the main thread.
    # If you want to display the camera image you can call it main.py.

    #0000FF å½“å‰æ§åˆ¶å‘½ä»¤
    global Drone_Controller, Total_Time, Draw, Explore_State

    Total_Time += dt # ç´¯è®¡æ—¶é—´

    # åˆ¤æ–­æ˜¯å¦ç¬¬ä¸€æ¬¡è¿è¡Œ
    if Drone_Controller is None:
        Drone_Controller = Class_Drone_Controller(sensor_data, camera_data)  # åˆ›å»ºæ— äººæœºæ§åˆ¶å™¨å¯¹è±¡
        print("Drone_Controller Created")

    # æ— äººæœºçŠ¶æ€æ›´æ–°
    Drone_Controller.update(sensor_data, camera_data) 

    # èµ·é£å‘½ä»¤
    if sensor_data['z_global'] < 2.0 and not Drone_Controller.takeoff:
        control_command = [sensor_data['x_global'], sensor_data['y_global'], sensor_data['z_global'] + 1.0, sensor_data['yaw']]
        if sensor_data['z_global'] > 1.2:
            Drone_Controller.takeoff = True
        return control_command
        
    # åœ¨æ¢ç´¢ä¸­ #FF0000
    if Explore_State == 0: # æ¢ç´¢çŠ¶æ€
        control_command = Drone_Controller.get_IMG_command()

        # æ¢ç´¢å®Œæ¯•æ ‡å¿—ä½
        if Drone_Controller.AT_GATE and Drone_Controller.RACING_EXPLORE == 5 or Total_Time > 25.0:

            # ä¿®æ”¹æ ‡å¿—ä½
            Explore_State = 1

            # ä¿å­˜æ•°æ®
            save_data(Drone_Controller.target_pos_list_buffer, file_name="target_positions")

            # æ•°æ®å¤„ç†
            data = AggregatedExtractor(Drone_Controller.target_pos_list_buffer) # ç›®æ ‡ç‚¹æ•°æ®å¤„ç†
            # points = data.convert_to_planning()
            # points = data.convert_to_planning_shift(0.2)                  # ä½¿ç”¨åç§»æ•°æ®ç«é€Ÿ
            points = data.convert_to_planning_shift_time_customized(0.2)  # ä½¿ç”¨åç§»æ•°æ®ç«é€Ÿ

            # æ ¹æ®ç›®æ ‡ç‚¹åˆ›å»ºè·¯å¾„ç‚¹é¡ºåº
            # é‡æ„ pathï¼Œå°† Gate 5 ç§»æ¤é¦–ä½ä½œä¸ºèµ·ç‚¹ï¼Œå¹¶ä¸”å†æ·»åŠ  Gate 5 ä½œä¸ºç»ˆç‚¹
            path_points = []
            path_points.append(Drone_Controller.Drone_POS_GLOBAL.tolist()) # å½“å‰ä½ç½®
            # path_points.append(points[-1])    # P5
            path_points.append([1, 4, 1])     # å›åˆ°èµ·ç‚¹
            path_points.extend(points[0:-1])  # P1 -> P4
            path_points.append(points[-1])    # P5
            path_points.append([1, 4, 1])     # å›åˆ°èµ·ç‚¹
            path_points.extend(points)        # P1 -> P5
            path_points.append([1, 4, 1])     # å›åˆ°èµ·ç‚¹
            path_points.extend(points)        # P1 -> P5 # æ·»åŠ ç¬¬ä¸‰åœˆé˜²æ­¢å‡ºäº‹
            path_points.append([1, 4, 1])     # å›åˆ°èµ·ç‚¹

            # åŸºäºä½ç½®çš„è·¯å¾„è§„åˆ’
            planner = MotionPlanner3D(obstacles=None, path=path_points)
            Drone_Controller.RACING_PATH = planner.trajectory_setpoints

            # æµ‹è¯•åŸºäºçš„æ—¶é—´è·¯å¾„
            Drone_Controller.racing_path = planner.trajectory_setpoints
            Drone_Controller.racing_time = planner.time_setpoints


     
    # æ¢ç´¢å®Œæ¯• #FF0000
    elif Explore_State == 1: # æ¢ç´¢å®Œæ¯•
        control_command = Drone_Controller.get_Racing_command_POS_BASED() # è·¯å¾„è§„åˆ’å‘½ä»¤
        # control_command = Drone_Controller.get_Racing_command_TIME_BASED(dt) # è·¯å¾„è§„åˆ’å‘½ä»¤


    return control_command 








############################################ å®šä¹‰ Filter ç±» ############################################
import numpy as np
from collections import defaultdict

class AggregatedExtractor:
    def __init__(self, data_list, gate_point=(4,4,4), dist_thresh=0.5,
                 angle_range=(45,135), cluster_dist=0.8):
        self.gate_center = np.array(gate_point, float)
        self.T, self.min_ang, self.max_ang = dist_thresh, *angle_range
        self.cluster_dist = cluster_dist

        # è¾“å…¥æ•°æ®ï¼šæ¯ä¸ªå…ƒç´ ä¸º shape (5,3) çš„ np.ndarrayï¼Œåˆ†åˆ«å¯¹åº” P0..P4
        self.data_list = data_list
        # æå–æ‰€æœ‰ P4 ä½œä¸ºä¸­å¿ƒç‚¹åºåˆ—
        self.points4 = np.array([d[4] for d in data_list], float)

        # è‡ªå»ºæ•°æ®å­˜å‚¨
        self.data_filtered              = None  # èšåˆåç‚¹ + æ–¹å‘
        self.data_filtered_sorted       = None  # æ’åºåçš„èšåˆç»“æœ
        self.data_filtered_sorted_shift = None  # å¹³ç§»è°ƒæ•´åçš„åæ ‡

        # ç”Ÿæˆæ‰‡åŒºåˆ’åˆ†ï¼Œå¹¶ç«‹å³æ‰§è¡Œèšåˆæµç¨‹
        self.generate_sector_angles()
        self.compute_conditional_idxs()
        self.sort_aggregated()

    def compute_mask(self):
        # åˆ¤æ–­ç›¸é‚» P4 ç‚¹ä½ç§»åŠ¨æ˜¯å¦å°äºé˜ˆå€¼
        dists = np.linalg.norm(np.diff(self.points4, axis=0), axis=1)
        mask = np.concatenate(([True], dists < self.T))
        return mask

    # åˆ¤æ–­è§’åº¦ + å‰ä¹˜ï¼Œè®¡ç®—ç´¢å¼•å¹¶èšåˆæ¯ä¸ªç°‡çš„ä¸­å¿ƒç‚¹ä¸å¹³å‡æ–¹å‘
    def compute_conditional_idxs(self):
        mask = self.compute_mask()
        idxs = []
        arrow_dict = {}
        # ç­›é€‰æ»¡è¶³è·ç¦»å’Œè§’åº¦æ¡ä»¶çš„ç´¢å¼•ï¼Œå¹¶è®¡ç®—ç®­å¤´æ–¹å‘
        for i, pt4 in enumerate(self.points4):
            if not mask[i]:
                continue
            v1 = pt4 - self.gate_center
            # P0 å’Œ P3
            p0, p3 = self.data_list[i][0], self.data_list[i][3]
            # è®¡ç®—æ‘„åƒæœºå…‰è½´æ–¹å‘
            theta = np.arctan2(*(p0[:2] - p3[:2])[::-1]) - np.pi/2
            v2 = np.array([np.cos(theta), np.sin(theta), 0.])
            # è®¡ç®—å¤¹è§’
            cosang = np.clip(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8), -1, 1)
            ang = np.degrees(np.arccos(cosang))
            if self.min_ang <= ang <= self.max_ang:
                idxs.append(i)
                # å¦‚æœ v1 ä¸ v2 çš„å‰ä¹˜åœ¨ z è½´ä¸ºè´Ÿï¼Œåˆ™åè½¬æ–¹å‘
                cross_z = np.cross(v1, v2)[2]
                arrow_dict[i] = -v2 if cross_z < 0 else v2

        # åŸºäºç©ºé—´è·ç¦»è¿›è¡Œèšç±»
        clusters, curr = [], [idxs[0]] if idxs else []
        for a, b in zip(idxs, idxs[1:]):
            if np.linalg.norm(self.points4[b] - self.points4[a]) < self.cluster_dist:
                curr.append(b)
            else:
                clusters.append(curr)
                curr = [b]
        if curr:
            clusters.append(curr)

        # èšåˆæ¯ä¸ªç°‡çš„ä¸­å¿ƒç‚¹ä¸å¹³å‡ç®­å¤´æ–¹å‘
        agg = []
        for cl in clusters:
            pts = self.points4[cl]
            center = pts.mean(axis=0)
            arrows = np.array([arrow_dict[i] for i in cl])
            avg_arrow = arrows.mean(axis=0)
            agg.append({'Point': center, 'Arrow': avg_arrow})

        self.data_filtered = agg
        return agg

    ############################################## æ‰‡åŒºåˆ’åˆ†ä¸æ’åº #######################################
    def generate_sector_angles(self):
        gate, none = np.deg2rad(35), np.deg2rad(25)
        base = -np.pi - gate/2 + gate + none
        self.sectors = [(base + i*(gate + none), base + i*(gate + none) + gate) for i in range(5)]

    def _sector(self, pt2d):
        ang = np.arctan2(*(pt2d - self.gate_center[:2])[::-1])
        for idx, (s, e) in enumerate(self.sectors):
            if s <= ang <= e:
                return f'Gate{idx}', idx
        return None, None

    def sort_aggregated(self):
        groups = defaultdict(list)
        for item in self.data_filtered:
            label, idx = self._sector(item['Point'][:2])
            if idx is not None:
                groups[idx].append((item['Point'], item['Arrow']))

        result = []
        for idx in sorted(groups):
            pts, arrs = zip(*groups[idx])
            mean_pt = np.mean(pts, axis=0)
            mean_arr = np.mean(arrs, axis=0)
            result.append((f'Gate{idx}', mean_pt, mean_arr))

        self.data_filtered_sorted = result

    def convert_to_planning(self):
        # è¿”å› [(x,y,z), ...]
        return [tuple(np.round(pt, 3)) for _, pt, _ in self.data_filtered_sorted]

    def convert_to_planning_shift(self, shift = 0.3):
        self.data_filtered_sorted_shift = []
        for label, center, arrow in self.data_filtered_sorted:
            angle = np.arctan2(arrow[1], arrow[0])
            new_dir = angle - np.pi/2
            new_vec = np.array([np.cos(new_dir), np.sin(new_dir), 0.])
            new_pt = center + shift * new_vec
            point = tuple(np.round(new_pt, 3))
            self.data_filtered_sorted_shift.append((label, point, arrow))
        return [pt for _, pt, _ in self.data_filtered_sorted_shift]

    def convert_to_planning_shift_time_customized(self, shift = 0.3):
        self.data_filtered_sorted_shift = []
        for label, center, arrow in self.data_filtered_sorted:
            angle = np.arctan2(arrow[1], arrow[0])
            new_dir = angle - np.pi/2
            new_vec = np.array([np.cos(new_dir), np.sin(new_dir), 0.])
            new_pt = center + shift * new_vec
            new_pt[2] -= 0.2 # åŸºäºæ—¶é—´å¯¼èˆªéœ€è¦é™ä½é«˜åº¦
            point = tuple(np.round(new_pt, 3))
            self.data_filtered_sorted_shift.append((label, point, arrow))
        return [pt for _, pt, _ in self.data_filtered_sorted_shift]
    


##################################################### å®šä¹‰è·¯å¾„è§„åˆ’ç±» ##############################################
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.art3d import Poly3DCollection

class MotionPlanner3D():
    
    #Question: SIMON PID, what is vel_max set for PID? Check should be same here
    def __init__(self, obstacles, path, DEBUG = False):

        self.path = path

        self.DEBUG = DEBUG

        self.trajectory_setpoints = None

        self.init_params(self.path)

        self.run_planner(obstacles, self.path) # è®¡ç®—æ‰€æœ‰æ•°æ®

        # ---------------------------------------------------------------------------------------------------- ##
    #00FF00 #00FF00
    # æ ¹æ®èµ·ç‚¹ï¼Œç»ˆç‚¹ï¼Œä»¥åŠç»è¿‡ç‚¹è§„åˆ’è½¨è¿¹
    def run_planner(self, obs, path_waypoints):    
        # Run the subsequent functions to compute the polynomial coefficients and extract and visualize the trajectory setpoints
         ## DO NOT MODIFY --------------------------------------------------------------------------------------- ##
    
        poly_coeffs = self.compute_poly_coefficients(path_waypoints)
        self.trajectory_setpoints, self.time_setpoints = self.poly_setpoint_extraction(poly_coeffs, obs, path_waypoints)

        ## ---------------------------------------------------------------------------------------------------- ##

    def init_params(self, path_waypoints):

        # Inputs:
        # - path_waypoints: The sequence of input path waypoints provided by the path-planner, including the start and final goal position: Vector of m waypoints, consisting of a tuple with three reference positions each as provided by AStar

        # TUNE THE FOLLOWING PARAMETERS (PART 2) ----------------------------------------------------------------- ##
        #00FF00
        self.disc_steps = 20    # Integer number steps to divide every path segment into to provide the reference positions for PID control # IDEAL: Between 10 and 20
        self.vel_lim    = 7.0   # Velocity limit of the drone (m/s)
        self.acc_lim    = 50.0  # Acceleration limit of the drone (m/sÂ²)
        t_f             = 30    # Final time at the end of the path (s)

        # Determine the number of segments of the path
        self.times = np.linspace(0, t_f, len(path_waypoints)) # The time vector at each path waypoint to traverse (Vector of size m) (must be 0 at start)

    def compute_poly_matrix(self, t):
        # Inputs:
        # - t: The time of evaluation of the A matrix (t=0 at the start of a path segment, else t >= 0) [Scalar]
        # Outputs: 
        # - The constraint matrix "A_m(t)" [5 x 6]
        # The "A_m" matrix is used to represent the system of equations [x, \dot{x}, \ddot{x}, \dddot{x}, \ddddot{x}]^T  = A_m(t) * poly_coeffs (where poly_coeffs = [c_0, c_1, c_2, c_3, c_4, c_5]^T and represents the unknown polynomial coefficients for one segment)
        A_m = np.zeros((5,6))
        
        # TASK: Fill in the constraint factor matrix values where each row corresponds to the positions, velocities, accelerations, snap and jerk here
        # SOLUTION ---------------------------------------------------------------------------------- ## 
        
        A_m = np.array([
            [t**5, t**4, t**3, t**2, t, 1],            # pos
            [5*(t**4), 4*(t**3), 3*(t**2), 2*t, 1, 0], # vel
            [20*(t**3), 12*(t**2), 6*t, 2, 0, 0],      # acc  
            [60*(t**2), 24*t, 6, 0, 0, 0],             # jerk
            [120*t, 24, 0, 0, 0, 0]                    # snap
        ])

        return A_m

    def compute_poly_coefficients(self, path_waypoints):
        
        
        seg_times = np.diff(self.times) # The time taken to complete each path segment
        m = len(path_waypoints)         # Number of path waypoints (including start and end)
        poly_coeffs = np.zeros((6*(m-1),3))

        # YOUR SOLUTION HERE ---------------------------------------------------------------------------------- ## 

        # 1. Fill the entries of the constraint matrix A and equality vector b for x,y and z dimensions in the system A * poly_coeffs = b. Consider the constraints according to the lecture: We should have a total of 6*(m-1) constraints for each dimension.
        # 2. Solve for poly_coeffs given the defined system

        for dim in range(3):  # Compute for x, y, and z separately
            A = np.zeros((6*(m-1), 6*(m-1)))
            b = np.zeros(6*(m-1))
            pos = np.array([p[dim] for p in path_waypoints])
            A_0 = self.compute_poly_matrix(0) # A_0 gives the constraint factor matrix A_m for any segment at t=0, this is valid for the starting conditions at every path segment

            # SOLUTION
            row = 0
            for i in range(m-1):
                pos_0 = pos[i] #Starting position of the segment
                pos_f = pos[i+1] #Final position of the segment
                # The prescribed zero velocity (v) and acceleration (a) values at the start and goal position of the entire path
                v_0, a_0 = 0, 0
                v_f, a_f = 0, 0
                A_f = self.compute_poly_matrix(seg_times[i]) # A_f gives the constraint factor matrix A_m for a segment i at its relative end time t=seg_times[i]
                if i == 0: # First path segment
                #     # 1. Implement the initial constraints here for the first segment using A_0
                #     # 2. Implement the final position and the continuity constraints for velocity, acceleration, snap and jerk at the end of the first segment here using A_0 and A_f (check hints in the exercise description)
                    A[row, i*6:(i+1)*6] = A_0[0] #Initial position constraint
                    b[row] = pos_0
                    row += 1
                    A[row, i*6:(i+1)*6] = A_f[0] #Final position constraint
                    b[row] = pos_f
                    row += 1
                    A[row, i*6:(i+1)*6] = A_0[1] #Initial velocity constraint
                    b[row] = v_0
                    row += 1
                    A[row, i*6:(i+1)*6] = A_0[2] #Initial acceleration constraint
                    b[row] = a_0
                    row += 1
                    #Continuity of velocity, acceleration, jerk, snap
                    A[row:row+4, i*6:(i+1)*6] = A_f[1:]
                    A[row:row+4, (i+1)*6:(i+2)*6] = -A_0[1:]
                    b[row:row+4] = np.zeros(4)
                    row += 4
                elif i < m-2: # Intermediate path segments
                #     # 1. Similarly, implement the initial and final position constraints here for each intermediate path segment
                #     # 2. Similarly, implement the end of the continuity constraints for velocity, acceleration, snap and jerk at the end of each intermediate segment here using A_0 and A_f
                    A[row, i*6:(i+1)*6] = A_0[0] #Initial position constraint
                    b[row] = pos_0
                    row += 1
                    A[row, i*6:(i+1)*6] = A_f[0] #Final position constraint
                    b[row] = pos_f
                    row += 1
                    #Continuity of velocity, acceleration, jerk and snap
                    A[row:row+4, i*6:(i+1)*6] = A_f[1:]
                    A[row:row+4, (i+1)*6:(i+2)*6] = -A_0[1:]
                    b[row:row+4] = np.zeros(4)
                    row += 4
                elif i == m-2: #Final path segment
                #     # 1. Implement the initial and final position, velocity and accelerations constraints here for the final path segment using A_0 and A_f
                    A[row, i*6:(i+1)*6] = A_0[0] #Initial position constraint
                    b[row] = pos_0
                    row += 1
                    A[row, i*6:(i+1)*6] = A_f[0] #Final position constraint
                    b[row] = pos_f
                    row += 1
                    A[row, i*6:(i+1)*6] = A_f[1] #Final velocity constraint
                    b[row] = v_f
                    row += 1
                    A[row, i*6:(i+1)*6] = A_f[2] #Final acceleration constraint
                    b[row] = a_f
                    row += 1
            # Solve for the polynomial coefficients for the dimension dim

            poly_coeffs[:,dim] = np.linalg.solve(A, b)   

        return poly_coeffs

    def poly_setpoint_extraction(self, poly_coeffs, obs, path_waypoints):

        # DO NOT MODIFY --------------------------------------------------------------------------------------- ##

        # Uses the class features: self.disc_steps, self.times, self.poly_coeffs, self.vel_lim, self.acc_lim
        x_vals, y_vals, z_vals = np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1))
        v_x_vals, v_y_vals, v_z_vals = np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1))
        a_x_vals, a_y_vals, a_z_vals = np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1)), np.zeros((self.disc_steps*len(self.times),1))

        # Define the time reference in self.disc_steps number of segements
        time_setpoints = np.linspace(self.times[0], self.times[-1], self.disc_steps*len(self.times))  # Fine time intervals

        # Extract the x,y and z direction polynomial coefficient vectors
        coeff_x = poly_coeffs[:,0]
        coeff_y = poly_coeffs[:,1]
        coeff_z = poly_coeffs[:,2]

        for i,t in enumerate(time_setpoints):
            seg_idx = min(max(np.searchsorted(self.times, t)-1,0), len(coeff_x) - 1)
            # Determine the x,y and z position reference points at every refernce time
            x_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[0],coeff_x[seg_idx*6:(seg_idx+1)*6])
            y_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[0],coeff_y[seg_idx*6:(seg_idx+1)*6])
            z_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[0],coeff_z[seg_idx*6:(seg_idx+1)*6])
            # Determine the x,y and z velocities at every reference time
            v_x_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[1],coeff_x[seg_idx*6:(seg_idx+1)*6])
            v_y_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[1],coeff_y[seg_idx*6:(seg_idx+1)*6])
            v_z_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[1],coeff_z[seg_idx*6:(seg_idx+1)*6])
            # Determine the x,y and z accelerations at every reference time
            a_x_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[2],coeff_x[seg_idx*6:(seg_idx+1)*6])
            a_y_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[2],coeff_y[seg_idx*6:(seg_idx+1)*6])
            a_z_vals[i,:] = np.dot(self.compute_poly_matrix(t-self.times[seg_idx])[2],coeff_z[seg_idx*6:(seg_idx+1)*6])

        yaw_vals = np.zeros((self.disc_steps*len(self.times),1))
        trajectory_setpoints = np.hstack((x_vals, y_vals, z_vals, yaw_vals))

        if self.DEBUG:
            self.plot(obs, path_waypoints, trajectory_setpoints)
            
        # Find the maximum absolute velocity during the segment
        vel_max = np.max(np.sqrt(v_x_vals**2 + v_y_vals**2 + v_z_vals**2))
        vel_mean = np.mean(np.sqrt(v_x_vals**2 + v_y_vals**2 + v_z_vals**2))
        acc_max = np.max(np.sqrt(a_x_vals**2 + a_y_vals**2 + a_z_vals**2))
        acc_mean = np.mean(np.sqrt(a_x_vals**2 + a_y_vals**2 + a_z_vals**2))
        
        # Check that it is less than an upper limit velocity v_lim
        assert vel_max <= self.vel_lim, "The drone velocity exceeds the limit velocity : " + str(vel_max) + " m/s"
        assert acc_max <= self.acc_lim, "The drone acceleration exceeds the limit acceleration : " + str(acc_max) + " m/sÂ²"

        # ---------------------------------------------------------------------------------------------------- ##

        return trajectory_setpoints, time_setpoints
    
    def plot_obstacle(self, ax, x, y, z, dx, dy, dz, color='gray', alpha=0.3):
        """Plot a rectangular cuboid (obstacle) in 3D space."""
        vertices = np.array([[x, y, z], [x+dx, y, z], [x+dx, y+dy, z], [x, y+dy, z],
                            [x, y, z+dz], [x+dx, y, z+dz], [x+dx, y+dy, z+dz], [x, y+dy, z+dz]])
        
        faces = [[vertices[j] for j in [0, 1, 2, 3]], [vertices[j] for j in [4, 5, 6, 7]], 
                [vertices[j] for j in [0, 1, 5, 4]], [vertices[j] for j in [2, 3, 7, 6]], 
                [vertices[j] for j in [0, 3, 7, 4]], [vertices[j] for j in [1, 2, 6, 5]]]
        
        ax.add_collection3d(Poly3DCollection(faces, color=color, alpha=alpha))
    
    def plot(self, obs, path_waypoints, trajectory_setpoints):

        # Plot 3D trajectory
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111, projection='3d')

        if obs is not None:
            for ob in obs:
                self.plot_obstacle(ax, ob[0], ob[1], ob[2], ob[3], ob[4], ob[5])

        ax.plot(trajectory_setpoints[:,0], trajectory_setpoints[:,1], trajectory_setpoints[:,2], label="Minimum-Jerk Trajectory", linewidth=2)
        ax.set_xlim(0, 8)
        ax.set_ylim(0, 8)
        ax.set_zlim(0, 4)

        # Plot waypoints
        waypoints_x = [p[0] for p in path_waypoints]
        waypoints_y = [p[1] for p in path_waypoints]
        waypoints_z = [p[2] for p in path_waypoints]
        ax.scatter(waypoints_x, waypoints_y, waypoints_z, color='red', marker='o', label="Waypoints")

        # Labels and legend
        ax.set_xlabel("X Position")
        ax.set_ylabel("Y Position")
        ax.set_zlabel("Z Position")
        ax.set_title("3D Motion planning trajectories")
        ax.legend()

        # ä¿¯è§†å›¾ï¼šelev=90ï¼ˆä¿¯è§†ï¼‰ï¼Œazim= -90(è°ƒæ•´æœå‘ï¼Œå¯æ ¹æ®éœ€è¦æ”¹æˆ0ã€180ç­‰)
        ax.view_init(elev=90, azim=-90)

        plt.show()

